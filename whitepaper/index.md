---
id: "index"
title: "Abstract"
slug: "/"
sidebar_label: "Abstract"
sidebar_position: 0
custom_edit_url: null
---

# Abstract
The launch of [Bitcoin](https://bitcoin.org/en/) in 2009 presented to the world two key technologies that would then underlie the concept of [Web 3.0](https://ethereum.org/en/developers/docs/web2-vs-web3/#top): a decentralized digital currency and blockchain with distributed consensus mechanism. The subsequent development of these technologies—and first and foremost, of the [Ethereum](https://ethereum.org/en/) network, which supported [Turing-complete](https://en.wikipedia.org/wiki/Turing_completeness) [smart contracts](https://en.wikipedia.org/wiki/Smart_contract)—gave rise to a multitude of brand new distributed systems and applications, which attracted millions of users and billions of dollars. Among them, there are [DeFi](https://en.wikipedia.org/wiki/Decentralized_finance), [NFT](https://en.wikipedia.org/wiki/Non-fungible_token), and [Blockchain Gaming](https://dappradar.com/rankings/category/games). Decentralized solutions proved to be highly popular—to the point that the existing capacity appeared to be unable to satisfy the rapidly growing demand. As a result, [transaction costs on the Ethereum network rose to the level of dozens and even hundreds of dollars.](https://etherscan.io/chart/avg-txfee-usd)

The key Web 3.0 concept is to create open, decentralized alternatives for all the platforms and applications at the core of modern Internet. There are quite a few ongoing projects at the moment that are trying to implement this idea. Little by little, they are filling the gaps currently existing in the decentralized world.
<p align="center">
  <img src={require('/static/whitepaper/images/Aspose.Words.eadada23-420a-41ad-915d-f5754283a2b7.001.png').default} />
</p>

But decentralization is not the only defining feature of the Web 3.0 concept. It is expected that the following technologies will play a key role in the future: Big Data, AI, IoT and VR/AR. These technologies require a lot of computational capacity and access to data, know-how and specific tools for creating cutting edge products. The lion’s share of the cloud services market at the moment is [controlled by only three corporations](https://www.canalys.com/newsroom/global-cloud-market-Q121). The same corporations and a number of other, similar entities also control most of the data and technologies that will be fundamental for the Internet of the future.

In addition to massive centralization of computational capacity, [the year 2020 also saw a serious shortage thereof](https://en.wikipedia.org/wiki/2020%E2%80%932021_global_chip_shortage). This is happening at the time when millions of GPUs worldwide are used [to mine cryptocurrencies](https://en.wikipedia.org/wiki/Proof_of_work) even though they could be deployed to help develop and promote AI solutions in such key areas as healthcare, logistics, education, etc.

On the other hand, exponential growth in the number of data sources and the volume and variety of data, as well as ever more complex algorithms for data processing, give rise to more serious requirements for data anonymization and confidential computing. In particular, to meet these requirements, CPU manufacturers have, for a number of years now, been honing the [Trusted Execution Environment (TEE)](https://en.wikipedia.org/wiki/Trusted_execution_environment) technology, which allows for executing code in an isolated environment, protecting data integrity and confidentiality.

Super Protocol uses the latest blockchain and TEE developments to create a universal decentralized protocol for distributed confidential computing. Super Protocol thus offers an alternative to traditional cloud service providers within the Web 3.0 concept and makes it possible for anyone to contribute to the development of innovative technologies for the future Internet.
# Goals
Data could be in three states: at rest, in transit and in use. Traditionally, a variety of encryption methods have been used to protect data in storage or during transmission. However, data remained vulnerable during processing. Confidential computing resorts to hardware protection during processing to solve this problem.

<p align="center">
  <img src={require('/static/whitepaper/images/Aspose.Words.eadada23-420a-41ad-915d-f5754283a2b7.002.png').default} />
</p>

Confidential computing is rapidly gaining popularity with modern providers of cloud services and consumers of such services at large companies. Google calls this a [breakthrough](https://cloud.google.com/confidential-computing) technology, while [Gartner anticipates](https://www.r3.com/gartner-2021-privacy-enhancing-computation/) that by 2025, 50% of large companies will be using confidential computing. However, unlike with traditional cloud services, where trust in the provider is key, Super Protocol is a decentralized trustless system, which makes confidential computing an indispensable element at the core of the protocol itself.

Even though demand for confidential computing, in and of itself, continues to grow, Super Protocol offers the market so much more. It is an open, decentralized platform that features infinite computational resource scalability, supports complete confidentiality at the hardware level and provides a unique environment for creating an ecosystem of thousands of data sources, algorithms for data processing and unique solutions in the areas of AI, IoT, VR/AR, etc. Furthermore, any developer, be it an individual or a large corporation, will enjoy equal opportunities with respect to making additional contributions to the ecosystem.

According to a [McKinsey study](https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/ecosystem-2-point-0-climbing-to-the-next-level), consumers and service providers alike put an ever larger emphasis on ecosystems: “Seven in ten consumers we surveyed said they value ecosystem offerings that simplify their purchase journey. Perhaps more surprisingly, 60 percent of US banks we surveyed said they were likely to form or join an ecosystem.” Furthermore, [McKinsey expects](https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/how-do-companies-create-value-from-digital-ecosystems) this trend to continue in the coming years: “The integrated network economy could represent a global revenue pool of $60 trillion in 2025 with a potential increase in total economy share from about 1 to 2 percent today to approximately 30 percent by 2025.”

But what if this ecosystem is open and decentralized? As 2020–2021 proved, the demand for such systems is so high that it is not discouraged even by sky-high transaction costs that have reached several hundred dollars on the Ethereum platform. A modern ecosystem owned by a large cloud service provider may offer hundreds of services, but it is still a closed ecosystem. Super Protocol, as a Web 3.0 alternative, allows for a potentially unlimited number of combinations of computational capacity, public and private data, and innovative services, integrated under the same open protocol.
## Target Audience
### Computational Resource Owners
Humanity's computer hardware history has come a long way from unique computational machines owned or operated by large corporations and universities to marketplaces where anyone can rent any amount of computational resources for any period of time.

Super Protocol seeks to offer computational resource owners an open, fully decentralized protocol based on a public blockchain, under which computing power could be provided directly to end users, bypassing intermediaries, all the while generating a guaranteed, stable stream of income.

At the moment, there is a large quantity of equipment on the market that is used for all kinds of for-profit computing, such as:

1. Classic cloud computing;
1. Cryptocurrency mining;
1. Different kinds of blockchain validation and computing;
1. GPU renting (for example, [Vast.ai](https://vast.ai/)).

Super Protocol is unique in that it allows equipment owners to engage in useful confidential computing of any complexity, generating a stable, predictable income stream.
### Data Owners
Data in the modern world is created everywhere, while new, more advanced processing algorithms allow for an ever larger number of ways to use this data. However, there are quite a few difficulties here. Thus, large volumes of this data are not originally public, which means they require anonymization or confidential computing.

Quality anonymization is not always possible without losing data utility. Additionally, many of today’s analytical tools allow for successful [data de-anonymization](https://www.cs.utexas.edu/~shmat/shmat_oak09.pdf) under many different circumstances: “To demonstrate its effectiveness on real-world networks, we show that a third of the users who can be verified to have accounts on both Twitter, a popular microblogging service, and Flickr, an online photo-sharing site, can be re-identified in the anonymous Twitter graph with only a 12% error rate.”

Just about any data owner would benefit from monetizing it—provided this does not hurt their business as a whole. This is confirmed by the broad development of technologies for big data analysis.

Super Protocol offers data owners a simple, convenient route for monetizing their data—with no intermediaries involved, and while maintaining full data confidentiality.
### Service Developers
Technologies tend to grow more complex over time, as evidenced, among other things, by AI development over the past decade. Consequently, technological solutions require more labor, more in-depth expertise, and more computational capacity. As development costs grow, the need for intellectual property protection becomes paramount. At the same time, any solutions in the quickly changing modern world must be constantly updated and allow for easy scalability.

It follows from the foregoing that it is becoming increasingly more difficult for software developers to promote their own solutions. This is especially true in the case of small companies and individual developers. High costs of computational resources (in particular, GPUs), a lack of convenient platforms for promoting and selling solutions, and the risk of know-how leaks are serious constraint factors affecting innovation.

Super Protocol solves all of those problems by offering developers a direct sales channel to consumers, bypassing intermediaries, as well as provides all the tools necessary for quickly scaling the solutions while protecting intellectual property.
### Consumers of Data Analysis and Services
Who owns the information, he owns the world, it was said. This old adage becomes ever more relevant with every new year passing. But the problem is that the exponential growth in the volumes and variety of data makes distilling the kernels of value out of it an increasingly difficult task. In addition to data access, one needs technology and methods for processing it the right way.

Successful companies are always on the lookout for new approaches that would allow them to interact with their respective target audiences in a precise and effective way, growing their sales and making their offerings ever more competitive. In the modern world, this is most often achieved through an effective use of all available data and information technologies.

Super Protocol offers an open, decentralized ecosystem of computational resources, innovative products and services, data sources (including those previously unavailable for confidentiality reasons), and data processing tools.
# High-Level Description of the Protocol
<p align="center">
  <img src={require('/static/whitepaper/images/Aspose.Words.eadada23-420a-41ad-915d-f5754283a2b7.003.png').default} />
</p>

At a high level, Super Protocol includes the interactions shown in the diagram. The interactions involve the following entities:

- **Provider Offers.** In a form of a provider offer, the provider offers its resources or values in exchange for certain rewards. The offer can fall into one of three categories:
  - **Input.** Offers of this type are used for cooperative processing within a trusted execution environment (TEE). These can be data offers or solution offers.
  - **Execution.** Offers for cooperative execution of input data and obtaining the result. These can be TEE offers.
  - **Output.** Offers for storing the results. These can be storage offers.

Let's take a closer look at the types of offers:

- **Data offer.** The provider offers its data for processing. As a rule, these offers impose restrictions on the range of solutions for processing and may impose restrictions on the TEE where the data is processed. To protect data from leaks, a mechanism for attestation and encryption of the data is used.
- **Solution offer.** The provider publishes the solution for execution. Possible solution types:
  - **Script.** It accepts one of the selected formats as input data and saves the result in a specific format. The code is usually fully public and can be verified.
  - **Application.** Executed in a controlled container. The result of the execution can be verified by the provider. All inputs and outputs are also strictly controlled. The code is usually closed or available for verification only to the provider.
  - **Container or deployed solution.** Executed separately, takes the specified parameters as input, and returns the result. As a rule, the solution is fully closed.


To protect the solution from leaks, an attestation and encryption mechanism is used for the container.

- **Storage offer.** The provider offers storage for the results.
- **TEE Offer.** The provider offers TEE areas for confidential computing. It also participates in consensus protocol to verify resources and receive rewards. Provides a special block with a public key for remote attestation and protection of input and output data and solutions.


Users can create their own value offer types and dependencies on other values by offer type.

- **Value Customer.** Uses the deployed infrastructure to acquire certain values in exchange for tokens.

The protocol supports order payment with tokens, deferred payments, and fines for bad providers. These capabilities improve the quality of providers' service and attract more value customers. The mechanisms are described in more detail in the "Tokenomics" section.
## Protocol use cases
### Confidential computing on demand
Super Protocol is based on confidential computing. Therefore, the basic use case involves renting computing power for a wide range of different tasks. The long-term goal of our protocol development is to create a full analog of the largest cloud service providers in the Web3 concept.

This scenario includes the following roles:

- User
- TEE provider
#### User
Super Protocol is for those who need decentralized, permissionless, trustless and easily scalable computing resources. Computing power can be rented either for a one-time task with a specific result or for an unlimited period of time.

Below is an inexhaustive list of tasks that can be solved within the scenario:

- Individual developers and companies:
  - Deploying development and testing environments
  - Deploying distributed industrial solutions: from simple services to complex web and mobile applications
- Data Scientists:
  - Preprocessing large datasets
  - Training heavy models
  - Deploying AI services
- Content creators:
  - Rendering photos and videos
  - 3D modeling

#### TEE provider
Super Protocol is a good alternative for mining. The versatility of the protocol ensures a relatively even use of all resources: CPU, GPU (in the future), RAM, storage, network. The same cannot be said about mining, which has repeatedly caused a serious shortage of graphics cards and power supply units on the market, and there were fears of [HDD and SSD shortages](https://www.tomshardware.com/news/hard-drive-ssd-shortages-imminent-if-new-cryptocurrency-blooms). Also, unlike mining, where multiple resources are used to continuously perform the same type of computation, Super Protocol resources are used to solve user problems, i.e., to constantly create new value.

Resources for the protocol can be provided both by individual owners of hardware that is currently idle and by professional hosts who can use the protocol to better utilize hardware and attract new customers.
### Solutions on demand
On-demand solutions are a logical extension of the previous scenario. In this case, the user takes advantage of the solutions prepared by the protocol providers.

This scenario includes the same roles as the previous one, and adds a new one—Solution Provider.
#### Solution Provider
Super Protocol offers solution developers a convenient platform to promote their products and scale with the growth in demand for solutions, leveraging as much of the capacity of TEE providers as needed to fulfill orders.

Providers can offer a choice of solution variants according to the table below:

|Solution variant|Examples|
| :- | :- |
|One-time use, no computing power included|<p>Solutions where the load, volume of data, and traffic are unpredictable:</p><p>- AI services: image classification, text translation, article title generation, etc.</p><p>- Services that require large computing power or large amount of traffic: e.g., processing large amount of data</p>|
|One-time use, computing power included|<p>Solutions that do not store data, and/or resource requirements are known in advance:</p><p>- Services for processing data from public sources with predictable resource costs: Wikipedia, social media</p><p>- Services for processing strictly regulated data sets: 10,000 pictures, 100,000 words in the text, etc.</p>|
|Rent, computing power not included|<p>Solutions where the load, volume of data, and traffic are unpredictable:</p><p>- Ready-to-use solutions for business: project management systems, CRM</p><p>- AI service rent for synchronous multiple requests: bots, classification of user comments</p>|
|Rent, computing power included|<p>Solutions that do not store data, and/or resource requirements are known in advance:</p><p>- Services for online processing of data streams: analysis of stock quotes, news</p><p>- Services for visualizing public data: blockchain network statistics</p>|
### Processing of sensitive data
Super Protocol gives owners of sensitive data a unique opportunity to monetize their data without the need to build a comprehensive infrastructure for data processing and protection—other providers can provide their own solutions, and Super Protocol will provide data protection at all stages of its processing.

The scenario includes the same roles as the previous one, and adds a new one—Data Provider.
#### Data provider
In the simplest scenario, the data provider may just give access to the data: processing solutions will come from other providers (the data provider can check and approve them for use), and computing power will be allocated as orders come in.

If maximum control over the data is required, the process can be set up so that the data provider independently verifies all data processing outputs before forwarding them to the customer.

Providers can offer data in several ways, as per the table below:

|Solution variant|Examples|
| :- | :- |
|One-time use, data only|A data set and list of pre-tested and approved solutions from other providers for data processing.|
|One-time use, complete solution|A turnkey solution that includes the data set, the solution for its processing (in-house or from another provider), and the necessary computing power.|
|Rent, data only|A data source and a list of pre-tested and approved solutions for data processing from other providers. Access to the data source is active as long as the rent is paid.|
|Rent, complete solution|A turnkey solution that includes the data source, the solution for data processing (in-house or from another provider), and the necessary computing power. The solution is provided as long as the user pays the rent.|

